{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DengAI Regression Notebook**\n",
    "This notebook contains regression based models for the DengAI competition\n",
    "\n",
    "### Environment and Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment is: keras\n"
     ]
    }
   ],
   "source": [
    "#Run the utils notebook\n",
    "%run DengAI-Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process the data\n",
    "df_x_train_sj, df_y_train_sj, df_x_test_sj, df_y_test_sj, df_x_valid_sj, df_y_valid_sj, df_x_pred_sj, df_y_pred_sj=pre_process_data(\n",
    "    city='sj',\n",
    "    train_split=0.8,\n",
    "    test_split=0.2,\n",
    "    valid_split=0.0,\n",
    "    xy_split=0.0,\n",
    "    time_series_split=True\n",
    ")\n",
    "#Pre-process data for iq\n",
    "df_x_train_iq, df_y_train_iq, df_x_test_iq, df_y_test_iq, df_x_valid_iq, df_y_valid_iq, df_x_pred_iq, df_y_pred_iq=pre_process_data(\n",
    "    city='iq',\n",
    "    train_split=0.8,\n",
    "    test_split=0.2,\n",
    "    valid_split=0.0,\n",
    "    xy_split=0.0,\n",
    "    time_series_split=True\n",
    ")\n",
    "\n",
    "#set target field\n",
    "target='total_cases'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Baseline\n",
    "Use a basic linear regression to establish the baseline model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score sj: 0.22\n",
      "Test set score sj: -0.37\n",
      "Training set score iq: 0.30\n",
      "Test set score iq: 0.08\n",
      "total_cases\n",
      "MAE of SJ: 22.93956851413918\n",
      "MAE of IQ: 8.304594216035644\n",
      "MAE of Combined: 17.602800442341028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#create and fit the model. Use the scaled training and test feature data against the unscaled target\n",
    "lr_sj=LinearRegression().fit(df_x_train_sj,df_y_train_sj[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score sj: {:.2f}'.format(lr_sj.score(df_x_train_sj,df_y_train_sj[target])))\n",
    "print('Test set score sj: {:.2f}'.format(lr_sj.score(df_x_test_sj,df_y_test_sj[target])))\n",
    "\n",
    "#create and fit the model. Use the scaled training and test feature data against the unscaled target\n",
    "lr_iq=LinearRegression().fit(df_x_train_iq,df_y_train_iq[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score iq: {:.2f}'.format(lr_iq.score(df_x_train_iq,df_y_train_iq[target])))\n",
    "print('Test set score iq: {:.2f}'.format(lr_iq.score(df_x_test_iq,df_y_test_iq[target])))\n",
    "print(target)\n",
    "evaluate_results(lr_sj,lr_iq,df_x_test_sj,df_x_test_iq,df_y_test_sj,df_y_test_iq,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create the submission file'''\n",
    "#Use the trained model to make predictions on the holdout set\n",
    "y_pred_sj=lr_sj.predict(df_x_pred_sj)\n",
    "y_pred_iq=lr_iq.predict(df_x_pred_iq)\n",
    "\n",
    "#Create the holdout file\n",
    "create_submit_file(y_pred_sj,y_pred_iq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use ridge regression as a comparative baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score sj: 0.13\n",
      "Test set score sj: -0.19\n",
      "Training set score iq: 0.09\n",
      "Test set score iq: -0.02\n",
      "MAE of SJ: 24.90159410921486\n",
      "MAE of IQ: 7.650982091168224\n",
      "MAE of Combined: 18.813142808727815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#create and fit the model. Use the scaled training and test feature data against the unscaled target\n",
    "rr_sj=Ridge(alpha=150).fit(df_x_train_sj,df_y_train_sj[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score sj: {:.2f}'.format(rr_sj.score(df_x_train_sj,df_y_train_sj[target])))\n",
    "print('Test set score sj: {:.2f}'.format(rr_sj.score(df_x_test_sj,df_y_test_sj[target])))\n",
    "\n",
    "#create and fit the model. Use the scaled training and test feature data against the unscaled target\n",
    "rr_iq=Ridge(alpha=150).fit(df_x_train_iq,df_y_train_iq[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score iq: {:.2f}'.format(rr_iq.score(df_x_train_iq,df_y_train_iq[target])))\n",
    "print('Test set score iq: {:.2f}'.format(rr_iq.score(df_x_test_iq,df_y_test_iq[target])))\n",
    "\n",
    "#Test MAE \n",
    "y_pred_sj=rr_sj.predict(df_x_test_sj)\n",
    "y_pred_iq=rr_iq.predict(df_x_test_iq)\n",
    "y_pred_combined=np.append(y_pred_sj,y_pred_iq)\n",
    "y_target_combined=np.append(df_y_test_sj[target],df_y_test_iq[target])\n",
    "print('MAE of SJ: '+ str(mean_absolute_error(df_y_test_sj[target],y_pred_sj)))\n",
    "print('MAE of IQ: '+ str(mean_absolute_error(df_y_test_iq[target],y_pred_iq)))\n",
    "print('MAE of Combined: ' + str(mean_absolute_error(y_target_combined,y_pred_combined)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score sj: 0.00\n",
      "Test set score sj: -0.48\n",
      "Training set score iq: 0.00\n",
      "Test set score iq: -0.08\n",
      "MAE of SJ: 28.80807828676783\n",
      "MAE of IQ: 7.877219047619047\n",
      "MAE of Combined: 21.420716202362375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#create and fit the model. Use the scaled training and test feature data against the unscaled target\n",
    "lasso_sj=Lasso(alpha=150).fit(df_x_train_sj,df_y_train_sj[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score sj: {:.2f}'.format(lasso_sj.score(df_x_train_sj,df_y_train_sj[target])))\n",
    "print('Test set score sj: {:.2f}'.format(lasso_sj.score(df_x_test_sj,df_y_test_sj[target])))\n",
    "\n",
    "#create and fit the model. Use the scaled training and test feature data against the unscaled target\n",
    "lasso_iq=Lasso(alpha=150).fit(df_x_train_iq,df_y_train_iq[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score iq: {:.2f}'.format(lasso_iq.score(df_x_train_iq,df_y_train_iq[target])))\n",
    "print('Test set score iq: {:.2f}'.format(lasso_iq.score(df_x_test_iq,df_y_test_iq[target])))\n",
    "\n",
    "#Test MAE \n",
    "y_pred_sj=lasso_sj.predict(df_x_test_sj)\n",
    "y_pred_iq=lasso_iq.predict(df_x_test_iq)\n",
    "y_pred_combined=np.append(y_pred_sj,y_pred_iq)\n",
    "y_target_combined=np.append(df_y_test_sj[target],df_y_test_iq[target])\n",
    "print('MAE of SJ: '+ str(mean_absolute_error(df_y_test_sj[target],y_pred_sj)))\n",
    "print('MAE of IQ: '+ str(mean_absolute_error(df_y_test_iq[target],y_pred_iq)))\n",
    "print('MAE of Combined: ' + str(mean_absolute_error(y_target_combined,y_pred_combined)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline using a Linear SVM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.07\n",
      "Test set score: 0.18\n",
      "Training set score: 0.04\n",
      "Test set score: -0.08\n",
      "MAE of SJ: 18.31039982659118\n",
      "MAE of IQ: 7.537959468706822\n",
      "MAE of Combined: 14.508362053220232\n",
      "-------------------------\n",
      "Submission File Creation complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "c=0.1\n",
    "e=30.0\n",
    "\n",
    "svm_reg_sj=LinearSVR(epsilon=e, C=c, random_state=42)\n",
    "svm_reg_sj.fit(df_x_train_sj,df_y_train_sj[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score: {:.2f}'.format(svm_reg_sj.score(df_x_train_sj,df_y_train_sj[target])))\n",
    "print('Test set score: {:.2f}'.format(svm_reg_sj.score(df_x_test_sj,df_y_test_sj[target])))\n",
    "\n",
    "svm_reg_iq=LinearSVR(epsilon=e, C=c,random_state=42)\n",
    "svm_reg_iq.fit(df_x_train_iq,df_y_train_iq[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score: {:.2f}'.format(svm_reg_iq.score(df_x_train_iq,df_y_train_iq[target])))\n",
    "print('Test set score: {:.2f}'.format(svm_reg_iq.score(df_x_test_iq,df_y_test_iq[target])))\n",
    "\n",
    "#Test MAE \n",
    "y_pred_sj=svm_reg_sj.predict(df_x_test_sj)\n",
    "y_pred_iq=svm_reg_iq.predict(df_x_test_iq)\n",
    "y_pred_combined=np.append(y_pred_sj,y_pred_iq)\n",
    "y_target_combined=np.append(df_y_test_sj[target],df_y_test_iq[target])\n",
    "print('MAE of SJ: '+ str(mean_absolute_error(df_y_test_sj[target],y_pred_sj)))\n",
    "print('MAE of IQ: '+ str(mean_absolute_error(df_y_test_iq[target],y_pred_iq)))\n",
    "print('MAE of Combined: ' + str(mean_absolute_error(y_target_combined,y_pred_combined)))\n",
    "\n",
    "#Use the trained model to make predictions on the holdout set\n",
    "y_pred_sj=svm_reg_sj.predict(df_x_pred_sj)\n",
    "y_pred_iq=svm_reg_iq.predict(df_x_pred_iq)\n",
    "\n",
    "#Create the holdout file\n",
    "create_submit_file(y_pred_sj,y_pred_iq)\n",
    "\n",
    "print('-'*25)\n",
    "print('Submission File Creation complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model Using Nonlinear SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.10\n",
      "Test set score: 0.15\n",
      "Training set score: 0.35\n",
      "Test set score: -0.11\n",
      "MAE of SJ: 17.823760292154823\n",
      "MAE of IQ: 7.743770861261916\n",
      "MAE of Combined: 14.266116963604384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_reg_sj=SVR(kernel='poly', degree=2, C=100, epsilon=0)\n",
    "svr_reg_sj.fit(df_x_train_sj,df_y_train_sj[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score: {:.2f}'.format(svr_reg_sj.score(df_x_train_sj,df_y_train_sj[target])))\n",
    "print('Test set score: {:.2f}'.format(svr_reg_sj.score(df_x_test_sj,df_y_test_sj[target])))\n",
    "\n",
    "svr_reg_iq=SVR(kernel='poly', degree=2, C=100, epsilon=0)\n",
    "svr_reg_iq.fit(df_x_train_iq,df_y_train_iq[target])\n",
    "\n",
    "#Look at scores\n",
    "print('Training set score: {:.2f}'.format(svr_reg_iq.score(df_x_train_iq,df_y_train_iq[target])))\n",
    "print('Test set score: {:.2f}'.format(svr_reg_iq.score(df_x_test_iq,df_y_test_iq[target])))\n",
    "\n",
    "#Test MAE \n",
    "y_pred_sj=svr_reg_sj.predict(df_x_test_sj)\n",
    "y_pred_iq=svr_reg_iq.predict(df_x_test_iq)\n",
    "y_pred_combined=np.append(y_pred_sj,y_pred_iq)\n",
    "y_target_combined=np.append(df_y_test_sj[target],df_y_test_iq[target])\n",
    "print('MAE of SJ: '+ str(mean_absolute_error(df_y_test_sj[target],y_pred_sj)))\n",
    "print('MAE of IQ: '+ str(mean_absolute_error(df_y_test_iq[target],y_pred_iq)))\n",
    "print('MAE of Combined: ' + str(mean_absolute_error(y_target_combined,y_pred_combined)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation complete\n"
     ]
    }
   ],
   "source": [
    "'''Create the submission file'''\n",
    "#Use the trained model to make predictions on the holdout set\n",
    "y_pred_sj=model_sj.predict(df_x_pred_sj)\n",
    "y_pred_iq=model_iq.predict(df_x_pred_iq)\n",
    "\n",
    "#Create the holdout file\n",
    "create_submit_file(y_pred_sj,y_pred_iq)\n",
    "\n",
    "print('Creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random forest regressor to get feature importances and select a set of features\n",
    "from sklearn.feature_selection import SelectFromModel,RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "select=RFE(RandomForestRegressor(n_estimators=100,random_state=1066),n_features_to_select=50)\n",
    "select.fit(df_x_train_sj_sc[training_feature_list],df_y_train_sj[target])\n",
    "df_x_train_sj_sc_l1=select.transform(df_x_train_sj_sc[training_feature_list])\n",
    "df_x_test_sj_sc_l1=select.transform(df_x_test_sj_sc[training_feature_list])\n",
    "\n",
    "print(df_x_train_sj_sc_l1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Several of the regression models yielded decent results for train and test. However, when they we applied to the holdout data, they did not generalize well. Presumably this is because the holdout cases involve severe outbreaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
