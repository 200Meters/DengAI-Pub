{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DengAI-Classifier\n",
    "Notebook to train a classifier which indicates whether or not the total cases is in a particular class of severity.\n",
    "\n",
    "This notebook tested whether or not a classifier could be created based on the test data to indicate the severity of an outbreak. The classifier was then applied to the holdout data to assign a severity. Severity has a high correlation to total_cases, so severity was used as an input feature to training several models including a DNN and BinomialRegression model. It should be noted that the training data has very few records which fall into the 'severe outbreak' category so SMOTE was employed to try to balance the dataset. Since this disrupts the time series, the models were trained using a random selection of data.\n",
    "\n",
    "#### Data and Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the utils notebook\n",
    "%run DengAI-Utils.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier without Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Load data\n",
    "df_i,df_l,df_h=load_all_data()\n",
    "df_h=load_holdout_data()\n",
    "df_i=interp(df_i)\n",
    "df_h=interp(df_h)\n",
    "\n",
    "#select each city\n",
    "df_i_sj=df_i[df_i['city']=='sj']\n",
    "df_h_sj=df_h[df_h['city']=='sj']\n",
    "df_l_sj=df_i_sj['outbreak_severity']\n",
    "\n",
    "df_i_sj=df_i_sj.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'])\n",
    "df_h_sj=df_h_sj.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'])\n",
    "\n",
    "df_i_iq=df_i[df_i['city']=='iq']\n",
    "df_h_iq=df_h[df_h['city']=='iq']\n",
    "df_l_iq=df_i_iq['outbreak_severity']\n",
    "df_i_iq.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'],inplace=True)\n",
    "df_h_iq.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'],inplace=True)\n",
    "\n",
    "#randomly segment in to train, test, valid\n",
    "df_x_train_sj,df_x_test_sj,df_y_train_sj,df_y_test_sj=train_test_split(df_i_sj,df_l_sj,test_size=0.2,random_state=42) #split to get the validation file\n",
    "#df_x_train_sj,df_x_test_sj,df_y_train_sj,df_y_test_sj=train_test_split(df_x_train_sj,df_y_train_sj,test_size=0.25,random_state=2) #further split to get train and test\n",
    "\n",
    "df_x_train_iq,df_x_test_iq,df_y_train_iq,df_y_test_iq=train_test_split(df_i_iq,df_l_iq,test_size=0.2,random_state=42) #split to get the validation file\n",
    "#df_x_train_iq,df_x_test_iq,df_y_train_iq,df_y_test_iq=train_test_split(df_x_train_iq,df_y_train_iq,test_size=0.25,random_state=0) #further split to get train and test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "rfc_sj=RandomForestClassifier(n_estimators=100,class_weight={0:18,1:88,2:96,3:99,4:99},max_depth=1)\n",
    "results_sj=rfc_sj.fit(df_x_train_sj,df_y_train_sj)\n",
    "\n",
    "y_pred_sj=rfc_sj.predict(df_x_test_sj)\n",
    "score_sj=rfc_sj.score(df_x_test_sj,df_y_test_sj)\n",
    "\n",
    "rfc_iq=RandomForestClassifier(n_estimators=100,class_weight={0:10,1:92,2:99},max_depth=5)\n",
    "results_iq=rfc_iq.fit(df_x_train_iq,df_y_train_iq)\n",
    "\n",
    "y_pred_iq=rfc_iq.predict(df_x_test_iq)\n",
    "score_iq=rfc_iq.score(df_x_test_iq,df_y_test_iq)\n",
    "\n",
    "print('Accuracy score for sj: ' + str(score_sj))\n",
    "print(confusion_matrix(df_y_test_sj,y_pred_sj))\n",
    "#print(classification_report(df_y_test_sj,y_pred_sj))\n",
    "print('-'*50)\n",
    "print('Accuracy score for iq: ' + str(score_iq))\n",
    "print(confusion_matrix(df_y_test_iq,y_pred_iq))\n",
    "#print(classification_report(df_y_test_iq,y_pred_iq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict holdout values\n",
    "#predict the values for the holdout set\n",
    "h_pred_sj=rfc_sj.predict(df_h_sj)\n",
    "h_pred_iq=rfc_iq.predict(df_h_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for sj: 0.9919678714859438\n",
      "[[165   3   0   0   0]\n",
      " [  0 141   1   0   0]\n",
      " [  2   0 146   0   0]\n",
      " [  0   0   0 143   0]\n",
      " [  0   0   0   0 146]]\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       168\n",
      "           1       0.98      0.99      0.99       142\n",
      "           2       0.99      0.99      0.99       148\n",
      "           3       1.00      1.00      1.00       143\n",
      "           4       1.00      1.00      1.00       146\n",
      "\n",
      "    accuracy                           0.99       747\n",
      "   macro avg       0.99      0.99      0.99       747\n",
      "weighted avg       0.99      0.99      0.99       747\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Accuracy score for iq: 0.9925650557620818\n",
      "--------------------------------------------------\n",
      "[[82  2  0]\n",
      " [ 0 99  0]\n",
      " [ 0  0 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        84\n",
      "           1       0.98      1.00      0.99        99\n",
      "           2       1.00      1.00      1.00        86\n",
      "\n",
      "    accuracy                           0.99       269\n",
      "   macro avg       0.99      0.99      0.99       269\n",
      "weighted avg       0.99      0.99      0.99       269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "#Load data\n",
    "df_i,df_l,df_h=load_all_data()\n",
    "df_h=load_holdout_data()\n",
    "df_i=interp(df_i)\n",
    "df_h=interp(df_h)\n",
    "\n",
    "#select each city\n",
    "df_i_sj=df_i[df_i['city']=='sj']\n",
    "df_h_sj=df_h[df_h['city']=='sj']\n",
    "df_l_sj=df_i_sj['outbreak_severity']\n",
    "\n",
    "df_i_sj=df_i_sj.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'])\n",
    "df_h_sj=df_h_sj.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'])\n",
    "\n",
    "df_i_iq=df_i[df_i['city']=='iq']\n",
    "df_h_iq=df_h[df_h['city']=='iq']\n",
    "df_l_iq=df_i_iq['outbreak_severity']\n",
    "df_i_iq.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'],inplace=True)\n",
    "df_h_iq.drop(columns=['city','week_start_date','outbreak_severity','year','total_cases','avg_total_cases_2_wks','cum_total_cases_2_wks'],inplace=True)\n",
    "\n",
    "#create smote records for each city dataset\n",
    "smt_sj=SMOTE(random_state=42)\n",
    "df_i_sj,df_l_sj=smt_sj.fit_sample(df_i_sj,df_l_sj)\n",
    "\n",
    "smt_iq=SMOTE(random_state=42)\n",
    "df_i_iq,df_l_iq=smt_iq.fit_sample(df_i_iq,df_l_iq)\n",
    "\n",
    "#Create test and train splits\n",
    "df_x_train_sj,df_x_test_sj,df_y_train_sj,df_y_test_sj=train_test_split(df_i_sj,df_l_sj,test_size=0.2,random_state=42) #split to get the validation file\n",
    "df_x_train_iq,df_x_test_iq,df_y_train_iq,df_y_test_iq=train_test_split(df_i_iq,df_l_iq,test_size=0.2,random_state=42) #split to get the validation file\n",
    "\n",
    "#Create random forest classifier and run the model\n",
    "rfc_sj=RandomForestClassifier(n_estimators=50,class_weight={0:18,1:88,2:96,3:99,4:99})\n",
    "results_sj=rfc_sj.fit(df_x_train_sj,df_y_train_sj)\n",
    "\n",
    "y_pred_sj=rfc_sj.predict(df_x_test_sj)\n",
    "score_sj=rfc_sj.score(df_x_test_sj,df_y_test_sj)\n",
    "\n",
    "rfc_iq=RandomForestClassifier(n_estimators=50,class_weight={0:10,1:92,2:99})\n",
    "results_iq=rfc_iq.fit(df_x_train_iq,df_y_train_iq)\n",
    "\n",
    "y_pred_iq=rfc_iq.predict(df_x_test_iq)\n",
    "score_iq=rfc_iq.score(df_x_test_iq,df_y_test_iq)\n",
    "\n",
    "print('Accuracy score for sj: ' + str(score_sj))\n",
    "print(confusion_matrix(df_y_test_sj,y_pred_sj))\n",
    "print('-'*50)\n",
    "print(classification_report(df_y_test_sj,y_pred_sj))\n",
    "print('-'*50)\n",
    "print('-'*50)\n",
    "print('Accuracy score for iq: ' + str(score_iq))\n",
    "print('-'*50)\n",
    "print(confusion_matrix(df_y_test_iq,y_pred_iq))\n",
    "print(classification_report(df_y_test_iq,y_pred_iq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict Class Values for Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the values for the holdout set\n",
    "h_pred_sj=rfc_sj.predict(df_h_sj)\n",
    "h_pred_iq=rfc_iq.predict(df_h_iq)\n",
    "\n",
    "#create a single series of results\n",
    "h_pred_combined=np.hstack((h_pred_sj,h_pred_iq))\n",
    "\n",
    "#save the estimated class labels to the holdout file\n",
    "df_h['outbreak_severity']=h_pred_combined\n",
    "df_h.to_csv('holdout_all.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test MAE Just Using Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.598743169398908"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "\n",
    "#Load data\n",
    "df_i,df_l,df_h=load_all_data()\n",
    "df_h=load_holdout_data()\n",
    "df_i=interp(df_i)\n",
    "df_h=interp(df_h)\n",
    "\n",
    "#select each city\n",
    "df_i_sj=df_i[df_i['city']=='sj']\n",
    "df_h_sj=df_h[df_h['city']=='sj']\n",
    "df_l_sj=df_l[df_l['city']=='sj']\n",
    "\n",
    "#Create test and train splits\n",
    "df_x_train_sj,df_x_test_sj,df_y_train_sj,df_y_test_sj=train_test_split(df_i_sj,df_l_sj,test_size=0.2,random_state=42) #split to get the validation file\n",
    "\n",
    "rfr=RandomForestRegressor(n_estimators=100,max_depth=6,criterion='mae',random_state=42)\n",
    "#score=(cross_val_score(rfr,df_x_train_sj['outbreak_severity'],df_y_train_sj['total_cases'],scoring='neg_mean_absolute_error',cv=3))\n",
    "\n",
    "df_x_train_sj=np.array(df_x_train_sj['outbreak_severity'])\n",
    "df_x_train_sj=np.reshape(df_x_train_sj,(-1,1))\n",
    "df_x_test_sj=np.array(df_x_test_sj['outbreak_severity'])\n",
    "df_x_test_sj=np.reshape(df_x_test_sj,(-1,1))\n",
    "df_x_train_sj.shape\n",
    "df_y_train_sj['total_cases'].shape\n",
    "\n",
    "rfr.fit(df_x_train_sj,df_y_train_sj['total_cases'])\n",
    "pred=rfr.predict(df_x_test_sj)\n",
    "mae_score=mean_absolute_error(pred,df_y_test_sj['total_cases'])\n",
    "mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Despite a good fit to the model, the severity score did not generalize well to the holdout set. Using the severity classifier in several models only reduced the accuracy of those models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
